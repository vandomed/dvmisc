% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/logreg_xerrors1.R
\name{logreg_xerrors1}
\alias{logreg_xerrors1}
\title{Logistic Regression with Normal Exposure Subject to Additive Normal Errors}
\usage{
logreg_xerrors1(y, xtilde, c = NULL, prev = NULL, samp_y1y0 = NULL,
  merror = TRUE, approx_integral = TRUE, integrate_tol = 1e-08,
  integrate_tol_hessian = integrate_tol, estimate_var = FALSE, ...)
}
\arguments{
\item{y}{Numeric vector of Y values.}

\item{xtilde}{List of numeric vectors with Xtilde values.}

\item{c}{Numeric matrix with \strong{C} values (if any), with
one row for each pool. Can be a vector if there is only 1 covariate.}

\item{prev}{Numeric value specifying disease prevalence, allowing for valid
estimation of the intercept with case-control sampling. Can specify
\code{samp_y1y0} instead if sampling rates are known.}

\item{samp_y1y0}{Numeric vector of length 2 specifying sampling probabilities
for cases and controls, allowing for valid estimation of the intercept with
case-control sampling. Can specify \code{prev} instead if it's easier.}

\item{merror}{Logical value for whether there is measurement error.}

\item{approx_integral}{Logical value for whether to use the probit
approximation for the logistic-normal integral, to avoid numerically
integrating X's out of the likelihood function.}

\item{integrate_tol}{Numeric value specifying \code{tol} input to
\code{\link[cubature]{hcubature}} for numerical integration.}

\item{integrate_tol_hessian}{Same as \code{integrate_tol}, but for use when
estimating the Hessian matrix only. Sometimes using a smaller value than for
likelihood maximization helps prevent cases where the inverse Hessian is not
positive definite.}

\item{estimate_var}{Logical value for whether to return variance-covariance
matrix for parameter estimates.}

\item{...}{Additional arguments to pass to \code{\link[stats]{nlminb}}.}
}
\value{
List containing:
\enumerate{
\item Numeric vector of parameter estimates.
\item Variance-covariance matrix (if \code{estimate_var = TRUE}).
\item Returned \code{\link[stats]{nlminb}} object from maximizing the
log-likelihood function.
\item Akaike information criterion (AIC).
}
}
\description{
Assumes exposure measurements are subject to additive normal measurement
errors, and exposure given covariates is a normal-errors linear regression.
Some replicates are required for identifiability. Parameters are estimated 
using maximum likelihood.
}
\details{
Disease model is:

logit[P(Y = 1|X, \strong{C})] = beta_0 + beta_x X + \strong{beta_c}^T 
\strong{C}

Measurement error model is:

Xtilde|X ~ N(0, sigsq_m)

Exposure model is:

X|\strong{C} ~ N(alpha_0 + \strong{alpha_c}^T \strong{C}, sigsq_x.c)
}
\examples{
# Load dataset - dat1 has (Y, X, C) values and dat1_xtilde is list with 1 or 
# 2 Xtilde measurements for each subject. True log-OR (beta_x) is 0.2.
data(dat1)
data(dat1_xtilde)

# Unobservable truth - use true X's
fit1 <- logreg_xerrors1(y = dat1$y, xtilde = dat1$x, c = dat1$c, 
                        merror = FALSE)
fit1$theta.hat

# Naive - use Xtilde's but ignore measurement error. Note that when merror is 
# set to FALSE, first Xtilde value for each subject is used.
fit2 <- logreg_xerrors1(y = dat1$y, xtilde = dat1_xtilde, c = dat1$c,
                        merror = FALSE)
fit2$theta.hat

# Corrected - use probit approximation to avoid numerical integration.
fit3 <- logreg_xerrors1(y = dat1$y, xtilde = dat1_xtilde, c = dat1$c,
                        merror = TRUE)
fit3$theta.hat


}
